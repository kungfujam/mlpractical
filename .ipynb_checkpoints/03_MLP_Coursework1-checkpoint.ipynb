{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Admin functions\n",
    "# https://ipython.org/ipython-doc/dev/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "# When modules are changed externally, uses latest version\n",
    "%autoreload 2\n",
    "# Lanches a console for interaction with this kernel (for testing)\n",
    "%qtconsole\n",
    "# If you get an error here, try running conda install ipyparallel and running again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework #1\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This coursework is concerned with building multi-layer networks to address the MNIST digit classification problem. It builds on the previous labs, in particular [02_MNIST_SLN.ipynb](02_MNIST_SLN.ipynb) in which single layer networks were trained for MNIST digit classification.   The course will involve extending that code to use Sigmoid and Softmax layers, combining these into multi-layer networks, and carrying out a number of MNIST digit classification experiments, to investigate the effect of learning rate, the number of hidden units, and the number of hidden layers.\n",
    "\n",
    "The coursework is divided into 4 tasks:\n",
    "* **Task 1**:   *Implementing a sigmoid layer* - 15 marks.  \n",
    "This task involves extending the `Linear` class in file `mlp/layers.py` to `Sigmoid`, with code for forward prop, backprop computation of the gradient, and weight update.\n",
    "* **Task 2**:  *Implementing a softmax layer* - 15 marks.  \n",
    "This task involves extending the `Linear` class in file `mlp/layers.py` to `Softmax`, with code for forward prop, backprop computation of the gradient, and weight update.\n",
    "* **Task 3**:  *Constructing a multi-layer network* - 40 marks.  \n",
    "This task involves putting together a Sigmoid and a Softmax layer to create a multi-layer network, with one hidden layer (100 units) and one output layer, that is trained to classify MNIST digits.  This task will include reporting classification results, exploring the effect of learning rates, and plotting Hinton Diagrams for the hidden units and output units.\n",
    "* **Task 4**:  *Experiments with different architectures*  - 30 marks.  \n",
    "This task involves further MNIST classification experiments, primarily looking at the effect of using different numbers of hidden layers.\n",
    "The coursework will be marked out of 100, and will contribute 30% of the total mark in the MLP course.\n",
    "\n",
    "## Previous Tutorials\n",
    "\n",
    "Before starting this coursework make sure that you have completed the first three labs:\n",
    "\n",
    "* [00_Introduction.ipynb](00_Introduction.ipynb) - setting up your environment; *Solutions*: [00_Introduction_solution.ipynb](00_Introduction_solution.ipynb)\n",
    "* [01_Linear_Models.ipynb](01_Linear_Models.ipynb) - training single layer networks; *Solutions*: [01_Linear_Models_solution.ipynb](01_Linear_Models_solution.ipynb)\n",
    "* [02_MNIST_SLN.ipynb](02_MNIST_SLN.ipynb) - training a single layer network for MNIST digit classification\n",
    "\n",
    "To ensure that your virtual environment is correct, please see [this note](https://github.com/CSTR-Edinburgh/mlpractical/blob/master/kernel_issue_fix.md) on the GitHub.\n",
    "## Submission\n",
    "**Submission Deadline:  Thursday 29 October, 16:00** \n",
    "\n",
    "Submit the coursework as an ipython notebook file, using the `submit` command in the terminal on a DICE machine. If your file is `03_MLP_Coursework1.ipynb` then you would enter:\n",
    "\n",
    "`submit mlp 1 03_MLP_Coursework1.ipynb` \n",
    "\n",
    "where `mlp 1` indicates this is the first coursework of MLP.\n",
    "\n",
    "After submitting, you should receive an email of acknowledgment from the system confirming that your submission has been received successfully. Keep the email as evidence of your coursework submission.\n",
    "\n",
    "**Please make sure you submit a single `ipynb` file (and nothing else)!**\n",
    "\n",
    "**Submission Deadline:  Thursday 29 October, 16:00** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "Please enter your exam number and the date in the next code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MLP Coursework 1\n",
    "#Exam number: B058714\n",
    "#Date: 20/10/2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the next code cell, which imports `numpy` and seeds the random number generator.  Please **do not** modify the random number generator seed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "#Seed a random number generator running the below cell, but do **not** modify the seed.\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "rng_state = rng.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Sigmoid Layer (15%)\n",
    "\n",
    "In this task you need to create a class `Sigmoid` which encapsulates a layer of sigmoid units.  You should do this by extending the `mlp.layers.Linear` class (in file `mlp/layers.py`), which implements a layer of linear units (i.e. weighted sum plus bias).  The `Sigmoid` class extends this by applying the sigmoid transfer function to the weighted sum in the forward propagation, and applying the derivative of the sigmoid in the gradient descent back propagation and computing the gradients with respect to layer's parameters. Do **not** copy the implementation provided in `Linear` class but rather, **reuse** it through inheritance.\n",
    "\n",
    "When you have implemented `Sigmoid` (in the `mlp.layers` module), then please test it by running the below code cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mlp.layers import Sigmoid\n",
    "\n",
    "a = numpy.asarray([-20.1, 52.4, 0, 0.05, 0.05, 49])\n",
    "b = numpy.asarray([-20.1, 52.4, 0, 0.05, 0.05, 49, 20, 20])\n",
    "\n",
    "rng.set_state(rng_state)\n",
    "sigm = Sigmoid(idim=a.shape[0], odim=b.shape[0], rng=rng)\n",
    "\n",
    "fp = sigm.fprop(a)\n",
    "deltas, ograds  = sigm.bprop(h=fp, igrads=b)\n",
    "\n",
    "print fp.sum()\n",
    "print deltas.sum()\n",
    "print ograds.sum()\n",
    "%precision 3\n",
    "print fp\n",
    "print deltas\n",
    "print ograds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "To include the `Sigmoid` code in the notebook please run the below code cell.  (The `%load` notebook command is used to load the source of the `Sigmoid` class from `mlp/layers.py`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load -s Sigmoid mlp/layers.py\n",
    "class Sigmoid(Linear):\n",
    "    \n",
    "    def get_name(self):\n",
    "        return 'sigmoid'\n",
    "    \n",
    "    ## Showing I could roll my own\n",
    "    # def sigmoid(self, X):\n",
    "    #     return 1. / (1 + numpy.exp(-X))\n",
    "    # expit is 10x faster http://stackoverflow.com/questions/21106134/numpy-pure-functions-for-performance-caching\n",
    "    def sigmoid(self, X):\n",
    "        return expit(X)\n",
    "    \n",
    "    def fprop(self, inputs):\n",
    "        a = super(Sigmoid, self).fprop(inputs)\n",
    "        return self.sigmoid(a)\n",
    "    \n",
    "    def bprop(self, h, igrads):\n",
    "        # h = Sigmoid(a) = 1. / (1 + numpy.exp(-a))\n",
    "        # dh/da = numpy.exp(-a) / (1 + numpy.exp(-a))**2\n",
    "        #       = h(1-h)\n",
    "        deltas = igrads * h * (1-h)\n",
    "        ograds = deltas.dot(self.W.T)\n",
    "        return deltas, ograds\n",
    "    \n",
    "    def bprop_cost(self, h, igrads, cost):\n",
    "        if cost is None or cost.get_name() == 'ce':\n",
    "            # for Sigmoid layer and cross entropy cost,\n",
    "            # cost back-prop is the same as standard back-prop\n",
    "            return self.bprop(h, igrads)\n",
    "        else:\n",
    "            raise NotImplementedError('Linear.bprop_cost method not implemented '\n",
    "                                      'for the %s cost' % cost.get_name())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Softmax (15%)\n",
    "\n",
    "In this task you need to create a class `Softmax` which encapsulates a layer of softmax units.  As in the previous task, you should do this by extending the `mlp.layers.Linear` class (in file `mlp/layers.py`).\n",
    "\n",
    "When you have implemented `Softmax` (in the `mlp.layers` module), then please test it by running the below code cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mlp.layers import Softmax\n",
    "\n",
    "a = numpy.asarray([-20.1, 52.4, 0, 0.05, 0.05, 49])\n",
    "b = numpy.asarray([0, 0, 0, 0, 0, 0, 0, 1])\n",
    "\n",
    "rng.set_state(rng_state)\n",
    "softmax = Softmax(idim=a.shape[0], odim=b.shape[0], rng=rng)\n",
    "\n",
    "fp = softmax.fprop(a)\n",
    "deltas, ograds = softmax.bprop_cost(h=None, igrads=fp-b, cost=None)\n",
    "\n",
    "print fp.sum()\n",
    "print deltas.sum()\n",
    "print ograds.sum()\n",
    "%precision 3\n",
    "print fp\n",
    "print deltas\n",
    "print ograds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "To include the `Softmax` code in the notebook please run the below code cell.  (The notebook `%load` command is used to load the source of the `Softmax` class from `mlp/layers.py`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load -s Softmax mlp/layers.py\n",
    "class Softmax(Linear):\n",
    "    def get_name(self):\n",
    "        return 'softmax'\n",
    "    \n",
    "    def softmax(self, X):\n",
    "        ## For matrices\n",
    "        ex = numpy.exp(X)\n",
    "        # Hack for a batch of size 1...must be a better way to deal with this\n",
    "        if ex.ndim == 1:\n",
    "            ex = ex[numpy.newaxis, :]\n",
    "        tot = numpy.sum(ex, axis=1, keepdims=True)\n",
    "        assert(tot.shape[0] == ex.shape[0]), \\\n",
    "            \"Total of exponents should be size N. Sum size %d, N from X is %d\" % (tot.shape[0], ex.shape[0])\n",
    "        return ex / tot\n",
    "#         ex = numpy.exp(x)\n",
    "#         tot = numpy.sum(ex)\n",
    "#         return ex / tot\n",
    "    \n",
    "    def fprop(self, inputs):\n",
    "        a = super(Softmax, self).fprop(inputs)\n",
    "        return self.softmax(a)\n",
    "    \n",
    "    # TODO: should probably NotImplementedError bprop and edit bprop_cost\n",
    "    def bprop(self, h, igrads):\n",
    "        # h = Softmax(a) = np.exp(a) / np.sum(np.exp(a))\n",
    "        # dh_c/da_k = h_c(\\dirac_ck - h_k)  #NB a matrix\n",
    "        # see end of lecture notes mlp05-hid\n",
    "        # USE AS TOP LAYER ONLY\n",
    "        ograds = numpy.dot(igrads, self.W.T)\n",
    "        return igrads, ograds\n",
    "        \n",
    "    def bprop_cost(self, h, igrads, cost):\n",
    "        if cost is None or cost.get_name() == 'ce':\n",
    "            # for softmax layer and cross entropy cost,\n",
    "            # cost back-prop is the same as standard back-prop\n",
    "            return self.bprop(h, igrads)\n",
    "        else:\n",
    "            raise NotImplementedError('Linear.bprop_cost method not implemented '\n",
    "                                      'for the %s cost' % cost.get_name())\n",
    "        return deltas, ograds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Multi-layer network for MNIST classification (40%)\n",
    "\n",
    "**(a)** (20%)  Building on the single layer linear network for MNIST classification used in lab [02_MNIST_SLN.ipynb](02_MNIST_SLN.ipynb), and using the `Sigmoid` and `Softmax` classes that you implemented in tasks 1 and 2, construct and learn a model that classifies MNIST images and:\n",
    "   * Has one hidden layer with a sigmoid transfer function and 100 units\n",
    "   * Uses a softmax output layer to discriminate between the 10 digit classes (use the `mlp.costs.CECost()` cost)\n",
    "\n",
    "Your code should print the final values of the error function and the classification accuracy for train, validation, and test sets (please keep also the log information printed by default by the optimiser). Limit the number of training epochs to 30. You can, of course, split your code across as many cells as you think is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# include here the complete code that constructs the model, performs training,\n",
    "# and prints the error and accuracy for train/valid/test\n",
    "\n",
    "import logging\n",
    "np = numpy\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "from mlp.layers import MLP, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "from mlp.dataset import MNISTDataProvider #import data provider\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateFixed\n",
    "\n",
    "rng = np.random.RandomState([2015,10,10])\n",
    "cost = CECost()\n",
    "model = MLP(cost=cost)\n",
    "model.add_layer(Sigmoid(idim=784, odim=100, rng=rng))\n",
    "model.add_layer(Softmax(idim=100, odim=10, rng=rng))\n",
    "# define the optimiser, here stochasitc gradient descent\n",
    "# with fixed learning rate and max_epochs as stopping criterion\n",
    "lr_scheduler = LearningRateFixed(learning_rate=0.01, max_epochs=30)\n",
    "optimiser = SGDOptimiser(lr_scheduler=lr_scheduler)\n",
    "\n",
    "logger.info('Initialising data providers...')\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=100, max_num_batches=-1, randomize=True)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=100, max_num_batches=-1, randomize=False)\n",
    "\n",
    "logger.info('Training started...')\n",
    "tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "logger.info('Testing the model on test set:')\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=100, max_num_batches=-1, randomize=False)\n",
    "cost, accuracy = optimiser.validate(model, test_dp)\n",
    "logger.info('MNIST test set accuracy is %.2f %% (cost is %.3f)'%(accuracy*100., cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** (10%) Investigate the impact of different learning rates $\\eta \\in \\{0.5, 0.2, 0.1, 0.05, 0.01, 0.005\\}$ on the convergence of the network training as well as the final accuracy:\n",
    "   * Plot (on a single graph) the error rate curves for each learning rate as a function of training epochs for training set\n",
    "   * Plot (on another single graph) the error rate curves as a function of training epochs for validation set\n",
    "   * Include a table of the corresponding error rates for test set\n",
    "\n",
    "The notebook command `%matplotlib inline` ensures that your graphs will be added to the notebook, rather than opened as additional windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learning rates to test\n",
    "# ======================\n",
    "learning_rates = [0.5, 0.2, 0.1, 0.05, 0.01, 0.005]\n",
    "\n",
    "\n",
    "# Create model objects\n",
    "# ====================\n",
    "import numpy as np\n",
    "from mlp.layers import MLP, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "from mlp.dataset import MNISTDataProvider #import data provider\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateFixed\n",
    "from copy import deepcopy\n",
    "\n",
    "rng = np.random.RandomState([2015,10,10])\n",
    "cost = CECost()\n",
    "model = MLP(cost=cost)\n",
    "model.add_layer(Sigmoid(idim=784, odim=100, rng=rng))\n",
    "model.add_layer(Softmax(idim=100, odim=10, rng=rng))\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=100, max_num_batches=-1, randomize=True)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=100, max_num_batches=-1, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=100, max_num_batches=-1, randomize=False)\n",
    "\n",
    "constantParams = {\n",
    "    'model': model,\n",
    "    'train_dp': train_dp,\n",
    "    'valid_dp': valid_dp,\n",
    "    'test_dp': test_dp\n",
    "}\n",
    "\n",
    "grid = [\n",
    "    dict(\n",
    "        deepcopy(constantParams).items() +\n",
    "        [\n",
    "            ('learning_rate', learning_rate),\n",
    "            ('lr_scheduler', LearningRateFixed(learning_rate=learning_rate, max_epochs=30)),\n",
    "            ('tr_stats', []),\n",
    "            ('valid_stats', []),\n",
    "            ('test_cost', None),\n",
    "            ('test_accuracy', None)\n",
    "        ]\n",
    "    )\n",
    "    for learning_rate in learning_rates\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training started with learning rate 0.500\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for random model is 2.344. Accuracy is 12.43%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for random model is 2.344. Accuracy is 12.92%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 0.575. Accuracy is 83.57%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.290. Accuracy is 91.49%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 3 seconds. Training speed 21250 pps. Validation speed 41891 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.286. Accuracy is 91.67%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.234. Accuracy is 93.27%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 3 seconds. Training speed 20343 pps. Validation speed 49009 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.234. Accuracy is 93.19%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.198. Accuracy is 94.50%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 3 seconds. Training speed 21828 pps. Validation speed 47038 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.199. Accuracy is 94.22%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.176. Accuracy is 95.22%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 3 seconds. Training speed 20821 pps. Validation speed 49790 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.173. Accuracy is 94.92%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.159. Accuracy is 95.71%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 3 seconds. Training speed 21381 pps. Validation speed 49237 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.153. Accuracy is 95.57%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.145. Accuracy is 95.97%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 2 seconds. Training speed 22112 pps. Validation speed 48469 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.137. Accuracy is 96.04%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.133. Accuracy is 96.33%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 2 seconds. Training speed 21835 pps. Validation speed 48070 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.124. Accuracy is 96.44%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.126. Accuracy is 96.59%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 3 seconds. Training speed 17857 pps. Validation speed 46531 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.113. Accuracy is 96.78%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.121. Accuracy is 96.66%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 3 seconds. Training speed 20484 pps. Validation speed 48132 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.104. Accuracy is 97.09%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.114. Accuracy is 96.91%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 3 seconds. Training speed 20063 pps. Validation speed 48226 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.097. Accuracy is 97.30%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.110. Accuracy is 96.97%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 3 seconds. Training speed 20851 pps. Validation speed 49834 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.090. Accuracy is 97.44%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.104. Accuracy is 97.14%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 2 seconds. Training speed 21859 pps. Validation speed 50003 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.084. Accuracy is 97.65%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.103. Accuracy is 97.08%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 2 seconds. Training speed 21983 pps. Validation speed 48217 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.078. Accuracy is 97.88%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.099. Accuracy is 97.18%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 3 seconds. Training speed 17619 pps. Validation speed 45790 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.074. Accuracy is 97.96%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.095. Accuracy is 97.34%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 3 seconds. Training speed 21737 pps. Validation speed 48426 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.069. Accuracy is 98.13%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.093. Accuracy is 97.33%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 3 seconds. Training speed 21937 pps. Validation speed 43872 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.065. Accuracy is 98.25%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.091. Accuracy is 97.36%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 2 seconds. Training speed 21898 pps. Validation speed 48773 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.061. Accuracy is 98.34%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.093. Accuracy is 97.37%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 2 seconds. Training speed 22099 pps. Validation speed 47677 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.058. Accuracy is 98.50%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.090. Accuracy is 97.42%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 3 seconds. Training speed 21760 pps. Validation speed 49145 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.055. Accuracy is 98.54%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.088. Accuracy is 97.44%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 3 seconds. Training speed 21730 pps. Validation speed 48818 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.052. Accuracy is 98.62%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.087. Accuracy is 97.59%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 3 seconds. Training speed 17797 pps. Validation speed 43117 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.050. Accuracy is 98.75%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.084. Accuracy is 97.51%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 3 seconds. Training speed 20453 pps. Validation speed 49880 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.047. Accuracy is 98.81%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.085. Accuracy is 97.59%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 3 seconds. Training speed 21501 pps. Validation speed 48753 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.045. Accuracy is 98.89%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.084. Accuracy is 97.51%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 3 seconds. Training speed 19566 pps. Validation speed 50202 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.043. Accuracy is 98.95%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.083. Accuracy is 97.56%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 3 seconds. Training speed 19227 pps. Validation speed 50382 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.041. Accuracy is 99.03%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.082. Accuracy is 97.59%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 3 seconds. Training speed 18552 pps. Validation speed 49474 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.039. Accuracy is 99.10%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.081. Accuracy is 97.57%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 3 seconds. Training speed 15696 pps. Validation speed 42340 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.037. Accuracy is 99.10%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.081. Accuracy is 97.60%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 3 seconds. Training speed 19089 pps. Validation speed 50174 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.035. Accuracy is 99.19%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.081. Accuracy is 97.57%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 3 seconds. Training speed 19522 pps. Validation speed 50497 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.034. Accuracy is 99.27%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.079. Accuracy is 97.61%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 3 seconds. Training speed 21745 pps. Validation speed 44646 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 97.73 % (cost is 0.076)\n",
      "INFO:root:Training started with learning rate 0.200\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for random model is 2.344. Accuracy is 12.43%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for random model is 2.344. Accuracy is 12.92%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 0.859. Accuracy is 77.99%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.387. Accuracy is 89.74%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 3 seconds. Training speed 21656 pps. Validation speed 49006 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.369. Accuracy is 89.71%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.303. Accuracy is 91.35%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 3 seconds. Training speed 20874 pps. Validation speed 47235 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.314. Accuracy is 91.01%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.272. Accuracy is 92.16%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 3 seconds. Training speed 20868 pps. Validation speed 48826 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.284. Accuracy is 91.75%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.251. Accuracy is 92.79%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 3 seconds. Training speed 20919 pps. Validation speed 39299 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.261. Accuracy is 92.42%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.234. Accuracy is 93.39%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 3 seconds. Training speed 17849 pps. Validation speed 50152 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.242. Accuracy is 92.98%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.220. Accuracy is 93.84%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 3 seconds. Training speed 21429 pps. Validation speed 45771 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.225. Accuracy is 93.49%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.206. Accuracy is 94.17%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 3 seconds. Training speed 21293 pps. Validation speed 46263 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.210. Accuracy is 93.97%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.195. Accuracy is 94.73%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 3 seconds. Training speed 21184 pps. Validation speed 45523 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.197. Accuracy is 94.36%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.185. Accuracy is 95.04%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 3 seconds. Training speed 21388 pps. Validation speed 42794 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.186. Accuracy is 94.60%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.177. Accuracy is 95.28%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 3 seconds. Training speed 20702 pps. Validation speed 54543 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.176. Accuracy is 94.88%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.167. Accuracy is 95.39%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 3 seconds. Training speed 21644 pps. Validation speed 34610 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.166. Accuracy is 95.20%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.164. Accuracy is 95.50%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 3 seconds. Training speed 18169 pps. Validation speed 44909 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.158. Accuracy is 95.47%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.156. Accuracy is 95.81%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 3 seconds. Training speed 18467 pps. Validation speed 44049 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.150. Accuracy is 95.65%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.151. Accuracy is 95.83%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 3 seconds. Training speed 19601 pps. Validation speed 46873 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.144. Accuracy is 95.85%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.145. Accuracy is 96.04%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 3 seconds. Training speed 15614 pps. Validation speed 52770 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.137. Accuracy is 96.03%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.142. Accuracy is 96.11%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 3 seconds. Training speed 17130 pps. Validation speed 51669 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.131. Accuracy is 96.25%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.135. Accuracy is 96.29%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 3 seconds. Training speed 18105 pps. Validation speed 32592 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.126. Accuracy is 96.40%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.134. Accuracy is 96.35%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 3 seconds. Training speed 15749 pps. Validation speed 36726 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.121. Accuracy is 96.55%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.128. Accuracy is 96.46%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 3 seconds. Training speed 19572 pps. Validation speed 54108 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.116. Accuracy is 96.64%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.125. Accuracy is 96.55%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 3 seconds. Training speed 20921 pps. Validation speed 52655 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.112. Accuracy is 96.85%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.123. Accuracy is 96.65%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 2 seconds. Training speed 21617 pps. Validation speed 54482 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.108. Accuracy is 96.98%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.119. Accuracy is 96.66%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 2 seconds. Training speed 21650 pps. Validation speed 53229 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.105. Accuracy is 97.08%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.116. Accuracy is 96.83%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 3 seconds. Training speed 21222 pps. Validation speed 53889 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.101. Accuracy is 97.20%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.115. Accuracy is 96.77%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 3 seconds. Training speed 21583 pps. Validation speed 53783 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.097. Accuracy is 97.31%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.113. Accuracy is 96.91%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 3 seconds. Training speed 21072 pps. Validation speed 54830 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.095. Accuracy is 97.38%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.111. Accuracy is 96.97%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 2 seconds. Training speed 21823 pps. Validation speed 55321 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.091. Accuracy is 97.50%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.110. Accuracy is 97.00%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 3 seconds. Training speed 18955 pps. Validation speed 46684 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.089. Accuracy is 97.57%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.107. Accuracy is 97.00%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 3 seconds. Training speed 19007 pps. Validation speed 49932 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.086. Accuracy is 97.69%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.105. Accuracy is 97.10%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 3 seconds. Training speed 18676 pps. Validation speed 53182 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.084. Accuracy is 97.75%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.104. Accuracy is 97.01%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 3 seconds. Training speed 18230 pps. Validation speed 54200 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 96.90 % (cost is 0.101)\n",
      "INFO:root:Training started with learning rate 0.100\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for random model is 2.344. Accuracy is 12.43%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for random model is 2.344. Accuracy is 12.92%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 1.216. Accuracy is 70.83%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.562. Accuracy is 87.63%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 3 seconds. Training speed 20580 pps. Validation speed 54669 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.490. Accuracy is 87.57%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.385. Accuracy is 89.72%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 3 seconds. Training speed 18631 pps. Validation speed 49011 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.388. Accuracy is 89.35%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.330. Accuracy is 90.86%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 3 seconds. Training speed 17757 pps. Validation speed 43291 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.345. Accuracy is 90.26%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.303. Accuracy is 91.42%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 3 seconds. Training speed 16005 pps. Validation speed 31412 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.320. Accuracy is 90.82%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.285. Accuracy is 91.76%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 4 seconds. Training speed 14576 pps. Validation speed 50900 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.302. Accuracy is 91.38%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.271. Accuracy is 92.18%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 3 seconds. Training speed 20629 pps. Validation speed 49838 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.287. Accuracy is 91.71%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.260. Accuracy is 92.65%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 3 seconds. Training speed 19937 pps. Validation speed 49795 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.275. Accuracy is 92.02%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.250. Accuracy is 92.81%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 3 seconds. Training speed 21015 pps. Validation speed 51269 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.263. Accuracy is 92.41%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.241. Accuracy is 93.14%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 3 seconds. Training speed 20720 pps. Validation speed 49210 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.253. Accuracy is 92.73%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.232. Accuracy is 93.47%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 3 seconds. Training speed 20926 pps. Validation speed 50222 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.244. Accuracy is 93.03%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.224. Accuracy is 93.58%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 3 seconds. Training speed 19338 pps. Validation speed 50366 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.235. Accuracy is 93.30%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.219. Accuracy is 93.90%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 3 seconds. Training speed 21085 pps. Validation speed 39480 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.227. Accuracy is 93.53%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.211. Accuracy is 93.96%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 3 seconds. Training speed 17507 pps. Validation speed 48111 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.219. Accuracy is 93.73%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.205. Accuracy is 94.32%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 3 seconds. Training speed 20806 pps. Validation speed 51047 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.212. Accuracy is 93.95%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.199. Accuracy is 94.55%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 3 seconds. Training speed 20729 pps. Validation speed 42029 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.205. Accuracy is 94.13%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.195. Accuracy is 94.58%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 3 seconds. Training speed 21578 pps. Validation speed 44250 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.198. Accuracy is 94.28%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.189. Accuracy is 94.95%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 3 seconds. Training speed 21164 pps. Validation speed 46141 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.192. Accuracy is 94.43%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.184. Accuracy is 95.18%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 3 seconds. Training speed 20769 pps. Validation speed 48319 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.186. Accuracy is 94.69%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.180. Accuracy is 95.21%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 3 seconds. Training speed 21360 pps. Validation speed 51304 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.181. Accuracy is 94.76%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.176. Accuracy is 95.29%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 3 seconds. Training speed 21211 pps. Validation speed 45707 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.176. Accuracy is 94.90%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.172. Accuracy is 95.32%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 3 seconds. Training speed 20769 pps. Validation speed 40819 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.171. Accuracy is 95.02%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.170. Accuracy is 95.42%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 3 seconds. Training speed 20929 pps. Validation speed 49209 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.166. Accuracy is 95.18%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.164. Accuracy is 95.50%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 3 seconds. Training speed 20481 pps. Validation speed 51438 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.162. Accuracy is 95.29%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.161. Accuracy is 95.59%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 3 seconds. Training speed 21169 pps. Validation speed 52267 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.158. Accuracy is 95.46%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.158. Accuracy is 95.71%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 3 seconds. Training speed 21405 pps. Validation speed 28453 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.154. Accuracy is 95.53%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.155. Accuracy is 95.76%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 3 seconds. Training speed 21082 pps. Validation speed 52487 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.150. Accuracy is 95.67%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.152. Accuracy is 95.90%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 2 seconds. Training speed 21746 pps. Validation speed 50868 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.147. Accuracy is 95.78%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.150. Accuracy is 95.96%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 3 seconds. Training speed 21444 pps. Validation speed 49901 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.143. Accuracy is 95.87%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.147. Accuracy is 95.99%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 3 seconds. Training speed 20882 pps. Validation speed 43812 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.140. Accuracy is 95.99%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.144. Accuracy is 96.10%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 3 seconds. Training speed 20941 pps. Validation speed 48100 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 95.84 % (cost is 0.145)\n",
      "INFO:root:Training started with learning rate 0.050\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for random model is 2.344. Accuracy is 12.43%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for random model is 2.344. Accuracy is 12.92%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 1.663. Accuracy is 60.81%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.975. Accuracy is 83.24%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 3 seconds. Training speed 19584 pps. Validation speed 38247 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.756. Accuracy is 83.45%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.559. Accuracy is 87.80%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 3 seconds. Training speed 18527 pps. Validation speed 51040 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.530. Accuracy is 87.06%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.438. Accuracy is 89.30%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 3 seconds. Training speed 20218 pps. Validation speed 51571 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.445. Accuracy is 88.43%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.383. Accuracy is 90.15%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 3 seconds. Training speed 21026 pps. Validation speed 49012 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.400. Accuracy is 89.15%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.350. Accuracy is 90.65%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 3 seconds. Training speed 19425 pps. Validation speed 46292 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.371. Accuracy is 89.80%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.330. Accuracy is 90.87%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 3 seconds. Training speed 17705 pps. Validation speed 49293 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.351. Accuracy is 90.21%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.314. Accuracy is 91.23%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 4 seconds. Training speed 15325 pps. Validation speed 41071 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.336. Accuracy is 90.53%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.302. Accuracy is 91.48%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 3 seconds. Training speed 17320 pps. Validation speed 33953 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.324. Accuracy is 90.81%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.292. Accuracy is 91.66%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 4 seconds. Training speed 14696 pps. Validation speed 32784 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.313. Accuracy is 91.06%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.284. Accuracy is 91.88%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 3 seconds. Training speed 16382 pps. Validation speed 41113 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.304. Accuracy is 91.27%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.277. Accuracy is 92.05%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 4 seconds. Training speed 14708 pps. Validation speed 48423 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.296. Accuracy is 91.51%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.270. Accuracy is 92.28%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 3 seconds. Training speed 15775 pps. Validation speed 32399 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.289. Accuracy is 91.68%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.264. Accuracy is 92.52%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 3 seconds. Training speed 19580 pps. Validation speed 40452 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.282. Accuracy is 91.81%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.259. Accuracy is 92.61%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 3 seconds. Training speed 20810 pps. Validation speed 48844 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.276. Accuracy is 92.02%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.255. Accuracy is 92.59%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 3 seconds. Training speed 21290 pps. Validation speed 49219 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.270. Accuracy is 92.21%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.249. Accuracy is 92.87%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 3 seconds. Training speed 20015 pps. Validation speed 46241 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.265. Accuracy is 92.38%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.245. Accuracy is 93.10%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 3 seconds. Training speed 20962 pps. Validation speed 48132 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.259. Accuracy is 92.54%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.240. Accuracy is 93.17%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 3 seconds. Training speed 18276 pps. Validation speed 47088 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.254. Accuracy is 92.69%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.236. Accuracy is 93.37%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 3 seconds. Training speed 19643 pps. Validation speed 47074 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.249. Accuracy is 92.79%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.232. Accuracy is 93.36%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 3 seconds. Training speed 20957 pps. Validation speed 46543 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.245. Accuracy is 92.98%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.229. Accuracy is 93.55%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 3 seconds. Training speed 21751 pps. Validation speed 46817 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.240. Accuracy is 93.13%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.225. Accuracy is 93.58%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 3 seconds. Training speed 20033 pps. Validation speed 46408 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.236. Accuracy is 93.27%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.222. Accuracy is 93.80%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 3 seconds. Training speed 17373 pps. Validation speed 37080 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.231. Accuracy is 93.40%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.218. Accuracy is 93.82%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 3 seconds. Training speed 20514 pps. Validation speed 47031 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.227. Accuracy is 93.52%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.214. Accuracy is 93.98%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 3 seconds. Training speed 21204 pps. Validation speed 49317 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.223. Accuracy is 93.63%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.211. Accuracy is 94.09%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 3 seconds. Training speed 21399 pps. Validation speed 49016 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.219. Accuracy is 93.73%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.209. Accuracy is 94.17%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 3 seconds. Training speed 21759 pps. Validation speed 48008 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.216. Accuracy is 93.82%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.205. Accuracy is 94.33%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 3 seconds. Training speed 21718 pps. Validation speed 47072 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.212. Accuracy is 93.89%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.202. Accuracy is 94.50%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 3 seconds. Training speed 21106 pps. Validation speed 47108 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.209. Accuracy is 94.02%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.199. Accuracy is 94.54%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 3 seconds. Training speed 20986 pps. Validation speed 47319 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 94.11 % (cost is 0.203)\n",
      "INFO:root:Training started with learning rate 0.010\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for random model is 2.344. Accuracy is 12.43%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for random model is 2.344. Accuracy is 12.92%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.214. Accuracy is 38.59%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 2.106. Accuracy is 56.35%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 3 seconds. Training speed 21424 pps. Validation speed 49554 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 1.978. Accuracy is 60.94%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 1.817. Accuracy is 65.91%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 3 seconds. Training speed 21088 pps. Validation speed 47927 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 1.659. Accuracy is 67.89%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 1.471. Accuracy is 71.98%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 3 seconds. Training speed 21033 pps. Validation speed 49545 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 1.343. Accuracy is 73.46%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 1.181. Accuracy is 77.94%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 3 seconds. Training speed 21395 pps. Validation speed 46324 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 1.102. Accuracy is 77.98%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.974. Accuracy is 82.48%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 3 seconds. Training speed 21191 pps. Validation speed 48493 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.934. Accuracy is 80.82%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.831. Accuracy is 84.31%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 3 seconds. Training speed 21514 pps. Validation speed 48793 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.817. Accuracy is 82.73%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.731. Accuracy is 85.51%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 3 seconds. Training speed 21782 pps. Validation speed 46568 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.732. Accuracy is 84.03%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.657. Accuracy is 86.44%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 3 seconds. Training speed 21140 pps. Validation speed 50140 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.669. Accuracy is 84.97%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.602. Accuracy is 87.38%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 3 seconds. Training speed 21541 pps. Validation speed 43636 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.621. Accuracy is 85.76%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.559. Accuracy is 87.86%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 3 seconds. Training speed 20568 pps. Validation speed 49289 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.582. Accuracy is 86.34%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.525. Accuracy is 88.27%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 3 seconds. Training speed 20371 pps. Validation speed 48112 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.551. Accuracy is 86.80%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.497. Accuracy is 88.59%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 3 seconds. Training speed 20383 pps. Validation speed 44037 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.525. Accuracy is 87.16%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.474. Accuracy is 88.87%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 3 seconds. Training speed 19764 pps. Validation speed 46912 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.503. Accuracy is 87.48%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.454. Accuracy is 89.10%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 3 seconds. Training speed 20695 pps. Validation speed 46691 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.484. Accuracy is 87.81%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.438. Accuracy is 89.27%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 3 seconds. Training speed 21112 pps. Validation speed 49594 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.468. Accuracy is 88.07%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.424. Accuracy is 89.38%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 3 seconds. Training speed 20790 pps. Validation speed 47624 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.454. Accuracy is 88.31%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.411. Accuracy is 89.76%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 3 seconds. Training speed 21368 pps. Validation speed 48881 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.442. Accuracy is 88.47%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.400. Accuracy is 89.89%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 3 seconds. Training speed 20986 pps. Validation speed 48443 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.431. Accuracy is 88.65%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.391. Accuracy is 89.95%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 3 seconds. Training speed 21266 pps. Validation speed 46574 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.422. Accuracy is 88.82%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.382. Accuracy is 90.11%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 3 seconds. Training speed 21525 pps. Validation speed 48727 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.413. Accuracy is 89.00%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.374. Accuracy is 90.14%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 3 seconds. Training speed 20904 pps. Validation speed 48364 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.405. Accuracy is 89.09%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.367. Accuracy is 90.32%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 3 seconds. Training speed 21174 pps. Validation speed 45487 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.398. Accuracy is 89.27%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.361. Accuracy is 90.28%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 3 seconds. Training speed 21303 pps. Validation speed 47510 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.391. Accuracy is 89.41%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.355. Accuracy is 90.53%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 3 seconds. Training speed 21053 pps. Validation speed 48239 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.385. Accuracy is 89.49%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.350. Accuracy is 90.55%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 3 seconds. Training speed 21582 pps. Validation speed 48155 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.380. Accuracy is 89.60%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.345. Accuracy is 90.64%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 3 seconds. Training speed 21447 pps. Validation speed 49044 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.374. Accuracy is 89.70%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.340. Accuracy is 90.68%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 3 seconds. Training speed 21569 pps. Validation speed 46380 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.370. Accuracy is 89.80%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.337. Accuracy is 90.73%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 3 seconds. Training speed 20969 pps. Validation speed 48345 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.365. Accuracy is 89.92%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.333. Accuracy is 90.90%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 3 seconds. Training speed 21208 pps. Validation speed 46815 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.361. Accuracy is 90.01%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.329. Accuracy is 91.01%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 3 seconds. Training speed 20874 pps. Validation speed 47447 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 90.58 % (cost is 0.340)\n",
      "INFO:root:Training started with learning rate 0.005\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for random model is 2.344. Accuracy is 12.43%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for random model is 2.344. Accuracy is 12.92%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.263. Accuracy is 26.82%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 2.212. Accuracy is 41.38%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 3 seconds. Training speed 21274 pps. Validation speed 48791 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 2.163. Accuracy is 49.99%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 2.106. Accuracy is 55.90%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 3 seconds. Training speed 21080 pps. Validation speed 50771 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 2.048. Accuracy is 59.12%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 1.975. Accuracy is 62.57%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 3 seconds. Training speed 21617 pps. Validation speed 44697 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 1.907. Accuracy is 63.47%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 1.818. Accuracy is 67.00%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 3 seconds. Training speed 21534 pps. Validation speed 48378 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 1.744. Accuracy is 66.78%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 1.644. Accuracy is 70.07%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 3 seconds. Training speed 21585 pps. Validation speed 47584 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 1.574. Accuracy is 69.58%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 1.472. Accuracy is 73.91%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 3 seconds. Training speed 21119 pps. Validation speed 49965 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 1.413. Accuracy is 72.48%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 1.315. Accuracy is 75.79%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 3 seconds. Training speed 21582 pps. Validation speed 45687 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 1.271. Accuracy is 74.90%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 1.180. Accuracy is 78.59%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 3 seconds. Training speed 21256 pps. Validation speed 46480 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 1.151. Accuracy is 77.08%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 1.067. Accuracy is 81.02%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 3 seconds. Training speed 21229 pps. Validation speed 48832 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 1.051. Accuracy is 79.03%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.973. Accuracy is 82.08%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 3 seconds. Training speed 20972 pps. Validation speed 49005 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.968. Accuracy is 80.33%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.896. Accuracy is 83.59%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 3 seconds. Training speed 21247 pps. Validation speed 47342 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.899. Accuracy is 81.53%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.831. Accuracy is 84.21%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 3 seconds. Training speed 21447 pps. Validation speed 47923 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.841. Accuracy is 82.40%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.776. Accuracy is 84.97%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 3 seconds. Training speed 21502 pps. Validation speed 45515 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.792. Accuracy is 83.15%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.730. Accuracy is 85.72%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 3 seconds. Training speed 21369 pps. Validation speed 48851 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.750. Accuracy is 83.77%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.691. Accuracy is 86.00%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 3 seconds. Training speed 21650 pps. Validation speed 48105 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.714. Accuracy is 84.33%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.657. Accuracy is 86.56%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 3 seconds. Training speed 21436 pps. Validation speed 48366 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.683. Accuracy is 84.81%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.628. Accuracy is 87.04%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 3 seconds. Training speed 21330 pps. Validation speed 49038 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.655. Accuracy is 85.20%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.602. Accuracy is 87.30%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 3 seconds. Training speed 21337 pps. Validation speed 49570 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.631. Accuracy is 85.58%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.579. Accuracy is 87.64%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 3 seconds. Training speed 21600 pps. Validation speed 45996 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.609. Accuracy is 85.97%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.559. Accuracy is 87.87%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 3 seconds. Training speed 20951 pps. Validation speed 49138 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.590. Accuracy is 86.25%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.541. Accuracy is 88.14%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 3 seconds. Training speed 21227 pps. Validation speed 47424 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.573. Accuracy is 86.49%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.524. Accuracy is 88.39%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 3 seconds. Training speed 21642 pps. Validation speed 47295 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.557. Accuracy is 86.74%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.510. Accuracy is 88.45%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 3 seconds. Training speed 21763 pps. Validation speed 47925 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.543. Accuracy is 86.91%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.497. Accuracy is 88.65%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 3 seconds. Training speed 21817 pps. Validation speed 48110 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.530. Accuracy is 87.15%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.485. Accuracy is 88.71%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 3 seconds. Training speed 18959 pps. Validation speed 47326 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.519. Accuracy is 87.27%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.474. Accuracy is 88.89%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 3 seconds. Training speed 19981 pps. Validation speed 40375 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.508. Accuracy is 87.42%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.464. Accuracy is 88.94%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 3 seconds. Training speed 20348 pps. Validation speed 48495 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.498. Accuracy is 87.55%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.454. Accuracy is 89.13%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 3 seconds. Training speed 19553 pps. Validation speed 49061 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.488. Accuracy is 87.72%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.446. Accuracy is 89.29%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 3 seconds. Training speed 19622 pps. Validation speed 44831 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.480. Accuracy is 87.82%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.438. Accuracy is 89.24%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 3 seconds. Training speed 19664 pps. Validation speed 45400 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 88.61 % (cost is 0.453)\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# ========\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "for config in grid:\n",
    "    optimiser = SGDOptimiser(lr_scheduler=config['lr_scheduler'])\n",
    "    logger.info('Training started with learning rate %0.3f' % config['learning_rate'])\n",
    "    config['tr_stats'], config['valid_stats'] = \\\n",
    "        optimiser.train(config['model'], config['train_dp'], config['valid_dp'])\n",
    "    logger.info('Testing the model on test set:')\n",
    "    config['test_cost'], config['test_accuracy'] = \\\n",
    "        optimiser.validate(config['model'], config['test_dp'])\n",
    "    logger.info('MNIST test set accuracy is %.2f %% (cost is %.3f)' % \\\n",
    "                (config['test_accuracy']*100., config['test_cost']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>test_cost</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.076271</td>\n",
       "      <td>0.9773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.101106</td>\n",
       "      <td>0.9690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.144611</td>\n",
       "      <td>0.9584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.203371</td>\n",
       "      <td>0.9411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.340147</td>\n",
       "      <td>0.9058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.453219</td>\n",
       "      <td>0.8861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  test_cost  test_accuracy\n",
       "0          0.500   0.076271         0.9773\n",
       "1          0.200   0.101106         0.9690\n",
       "2          0.100   0.144611         0.9584\n",
       "3          0.050   0.203371         0.9411\n",
       "4          0.010   0.340147         0.9058\n",
       "5          0.005   0.453219         0.8861"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEKCAYAAADticXcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cf2e1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEKCAYAAADticXcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/DGCcxjOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cf2e5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Plot (on a single graph) the error rate curves for each learning rate as a function of training epochs for training set\n",
    "tmp = [m['tr_stats'] for m in grid]\n",
    "df = pd.DataFrame(np.array([np.array(i)[:,1] for i in tmp]).T, columns=learning_rates)\n",
    "df.plot().set_title('Training Accuracy (%)')\n",
    "\n",
    "# Plot (on another single graph) the error rate curves as a function of training epochs for validation set\n",
    "tmp = [m['valid_stats'] for m in grid]\n",
    "df = pd.DataFrame(np.array([np.array(i)[:,1] for i in tmp]).T, columns=learning_rates)\n",
    "df.plot().set_title('Validation Accuracy (%)')\n",
    "\n",
    "# Include a table of the corresponding error rates for test set\n",
    "testres = pd.DataFrame(grid)[['learning_rate', 'test_cost', 'test_accuracy']]\n",
    "testres\n",
    "\n",
    "# plt.subplot(211)\n",
    "# for learning_rate\n",
    "# plt.plot([1,2,3], label=\"test1\")\n",
    "# plt.plot([3,2,1], label=\"test2\")\n",
    "# # Place a legend above this legend, expanding itself to\n",
    "# # fully use the given bounding box.\n",
    "# plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "#            ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "# plt.subplot(223)\n",
    "# plt.plot([1,2,3], label=\"test1\")\n",
    "# plt.plot([3,2,1], label=\"test2\")\n",
    "# # Place a legend to the right of this smaller figure.\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high training and validation accuracy for the higher learning rates is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** (10%) Plot the following graphs:\n",
    "  * Display the 784-element weight vector of each of the 100 hidden units as 10x10 grid plot of 28x28 images, in order to visualise what features of the input they are encoding.  To do this, take the weight vector of each hidden unit, reshape to 28x28, and plot using the `imshow` function).\n",
    "  * Plot a Hinton Diagram of the output layer weight matrix for digits 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `hinton` for plotting hinton diagrams was taken from the matplotlib examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def hinton(matrix, max_weight=None, ax=None):\n",
    "    \"\"\"Draw Hinton diagram for visualizing a weight matrix.\"\"\"\n",
    "    ax = ax if ax is not None else plt.gca()\n",
    "\n",
    "    if not max_weight:\n",
    "        max_weight = 2**np.ceil(np.log(np.abs(matrix).max())/np.log(2))\n",
    "\n",
    "    ax.patch.set_facecolor('gray')\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "    ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "    for (x,y),w in np.ndenumerate(matrix):\n",
    "        color = 'white' if w > 0 else 'black'\n",
    "        size = np.sqrt(np.abs(w))\n",
    "        rect = plt.Rectangle([x - size / 2, y - size / 2], size, size,\n",
    "                             facecolor=color, edgecolor=color)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    ax.autoscale_view()\n",
    "    ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigmoid_Ws = [config['model'].layers[0].W for config in grid]\n",
    "\n",
    "# So that all plots are relative, find the min and max values over all models\n",
    "max_w = np.max([(np.max(W), np.min(W)) for W in sigmoid_Ws])\n",
    "min_w = np.min([(np.max(W), np.min(W)) for W in sigmoid_Ws])\n",
    "for i, W in enumerate(sigmoid_Ws):\n",
    "    fig, axList = plt.subplots(10, 10)\n",
    "    axList = axList.flatten()\n",
    "    for ax in axList:\n",
    "        hinton(W, max_weight=max_w, ax=ax)\n",
    "    fig.set_size_inches(10, 10)\n",
    "    fig.suptitle(\"Model weights for learning rate %0.3f\" % learning_rates[i])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 4 - Experiments with 1-5 hidden layers (30%)\n",
    "\n",
    "In this task use the learning rate which resulted in the best accuracy in your experiments in Task 3 (b).  Perform the following experiments:\n",
    "\n",
    "  * Train a similar model to Task 3, with one hidden layer, but with 800 hidden units. \n",
    "  * Train 4 additional models with 2, 3, 4 and 5 hidden layers.  Set the number of hidden units for each model, such that all the models have similar number of trainable weights ($\\pm$2%).   For simplicity, for a given model, keep the number of units in each hidden layer the same.\n",
    "  * Plot value of the error function for training and validation sets as a function of training epochs for each model\n",
    "  * Plot the test set classification accuracy as a function of the number of hidden layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is the end of coursework 1.\n",
    "\n",
    "Please remember to save your notebook, and submit your notebook following the instructions at the top.  Please make sure that you have executed all the code cells when you submit the notebook.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
